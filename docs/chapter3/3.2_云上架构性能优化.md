# 3.2 云上架构性能优化（深度扩充版）

## 课程简介

云上架构性能优化不是单一产品的堆砌，而是对请求链路的“精雕细琢”。本课程将从**分层架构**出发，深度解析**CDN 全局调度原理**、**Redis 缓存三大难题解决方案**、以及**消息队列在不同业务场景下的深度应用**（包括具体的串并行计算对比、秒杀削峰流程、Pulsar/RocketMQ 高级特性）。

### 学习目标

- ✓ **全链路视角**：掌握从用户端到数据库端的 6 层优化逻辑。
- ✓ **CDN 深度原理**：理解 GSLB 如何做智能调度，以及动态加速（ECDN）的实现机制。
- ✓ **缓存攻防**：精通缓存雪崩、击穿、穿透的原理及**代码级**解决方案。
- ✓ **MQ 深度应用**：通过具体数值对比理解“异步解耦”，掌握秒杀场景的“削峰”架构。
- ✓ **TDMQ 家族精通**：区分 CKafka、Pulsar、RocketMQ 的底层差异及订阅模式。

---

# 第一部分：全链路分层架构与优化策略

> **本部分导读**  
> 一个高性能的架构，就像一个漏斗，层层过滤流量，层层提升效率。

## 一、分层架构详解

我们在设计架构时，通常遵循“漏斗模型”：

```
graph TD
    User[1. 用户接入层] -->|DNS/GSLB| CDN[2. 内容分发层 (CDN)]
    CDN -->|过滤静态流量| CLB[3. 应用接入层 (CLB)]
    CLB -->|七层转发| App[4. 应用服务层 (CVM/TKE)]
    App -->|热点读取| Cache[5. 缓存层 (Redis)]
    App -->|异步写入| MQ[6. 中间件层 (TDMQ)]
    Cache -->|持久化| DB[7. 数据层 (TDSQL)]
```

### 1.1 各层优化关键点

| 层级 | 关键技术/组件 | 优化手段 | 作用 |
| :--- | :--- | :--- | :--- |
| **用户接入** | **HttpDNS / GSLB** | 智能解析，就近接入 | 解决域名劫持，降低首字节时间 (TTFB)。 |
| **内容分发** | **CDN / ECDN** | 静态缓存 + 动态路由优化 | 将 80% 的静态流量拦截在边缘，减少回源。 |
| **应用接入** | **CLB (L4/L7)** | 会话保持、压缩、SSL 卸载 | 均衡后端负载，防止单点过载。 |
| **应用层** | **微服务 / 弹性伸缩** | 异步化、无状态设计 | 提升计算效率，应对突发流量。 |
| **缓存层** | **Redis / Memcached** | 热点缓存、读写分离 | 拦截 90% 的数据库读请求，降低 I/O 延迟。 |
| **中间件** | **CKafka / RocketMQ** | 削峰填谷、解耦 | 保护后端，将同步等待变为异步处理。 |
| **数据层** | **读写分离 / 分库分表** | 主从复制、冷热分离 | 提升数据库吞吐量。 |

---

# 第二部分：CDN 核心原理与动态加速

## 一、GSLB 智能调度原理

**GSLB (Global Server Load Balancing)** 是 CDN 的大脑。它不仅仅是看物理距离，而是基于多维指标进行调度：

1.  **地理位置**：用户 IP 归属地（如 北京）。
2.  **运营商**：用户所属网络（如 联通）。
3.  **节点负载**：边缘节点的 CPU、带宽利用率（避免调度到过载节点）。
4.  **链路质量**：实时探测的网络丢包率和延迟。

**案例**：北京联通用户 -> GSLB 判断 -> 北京联通节点负载 90% (过高) -> **调度至 天津联通节点 (负载 20%)**。虽然物理距离稍远，但响应更快。

## 二、动态加速 (ECDN) 

很多同学问：**API 接口、登录请求不能缓存，CDN 有用吗？**
答案是：**有用，使用 ECDN (全站加速)。**

**优化原理**：
1.  **链路优化**：CDN 节点与源站之间建立**长连接池**，避免每次请求都进行 TCP 三次握手和 SSL 四次握手。
2.  **智能路由**：绕过公网拥堵节点，选择一条最快的“内网高速公路”回源。
3.  **协议优化**：支持 QUIC 协议，在弱网环境下传输更稳定。

---

# 第三部分：缓存架构深度解析 (Redis)

## 一、缓存三大“顽疾”与解决方案

这是架构设计中最容易出故障的地方，请务必掌握：

### 1.1 缓存雪崩 (Cache Avalanche)
- **现象**：Redis 挂了，或者大量 Key 在**同一时刻集体过期**。
- **后果**：所有请求瞬间打到数据库，数据库 CPU 飙升至 100% 宕机。
- **解决方案**：
    - **过期时间随机化**：设置 TTL 时，添加一个随机值（如 `TTL = 10分钟 + Random(1~60秒)`）。
    - **高可用架构**：使用 Redis 集群版或主从版，避免单点故障。
    - **限流降级**：当数据库压力过大时，网关层直接拒绝部分非核心请求。

### 1.2 缓存击穿 (Hot Key Breakdown)
- **现象**：某个**超级热点 Key**（如微博热搜第一名）突然过期。
- **后果**：海量并发请求同时发现缓存失效，同时去查数据库，击垮 DB。
- **解决方案**：
    - **互斥锁 (Mutex Lock)**：第一个线程发现失效，加锁去查 DB 并回写缓存，其他线程等待。
    - **永不过期**：物理不过期，逻辑上异步更新（设置逻辑过期时间）。

### 1.3 缓存穿透 (Cache Penetration)
- **现象**：用户查询一个**根本不存在的数据**（如 `id = -1`），缓存没命中，数据库也查不到（因此没法回写缓存）。
- **后果**：黑客利用此漏洞发起攻击，请求全部穿透到数据库。
- **解决方案**：
    - **缓存空对象**：DB 查不到也缓存一个 `null`，设置较短过期时间。
    - **布隆过滤器 (Bloom Filter)**：在访问缓存前，先判断 key 是否存在，不存在直接拦截。

## 二、Redis 读写策略

推荐使用 **Cache Aside Pattern (旁路缓存模式)**：
1.  **读**：先读 Cache -> 命中返回；未命中读 DB -> 写入 Cache -> 返回。
2.  **写**：**先更新 DB，再删除 Cache**（注意是删除，不是更新，防止并发脏数据）。

---

# 第四部分：消息队列深度场景与数值对比

## 一、异步解耦：串行 vs 并行 vs 异步

**场景**：用户注册成功后，需发送注册邮件（100ms）和开户短信（100ms），写入用户库耗时 100ms。

### 1.1 方案对比

| 模式 | 流程描述 | 总耗时计算 | 特点 |
| :--- | :--- | :--- | :--- |
| **串行处理** | 写库 -> 发邮件 -> 发短信 | 100 + 100 + 100 = **300ms** | 逻辑简单，体验最差，吞吐量低。 |
| **并行处理** | 写库 -> (同时发邮件 + 发短信) | 100 + Max(100, 100) = **200ms** | 需消耗额外线程资源，复杂度增加。 |
| **异步处理 (MQ)** | 写库 -> **写入 MQ (5ms)** -> 返回 | 100 + 5 = **105ms** | **响应最快**，非核心逻辑后台慢慢跑。 |

**结论**：引入 MQ 后，系统吞吐量（QPS）理论上可以提升 **3倍** 左右。

## 二、秒杀场景：削峰填谷

**背景**：双 11 秒杀，商品 100 件，瞬间涌入 100 万请求。

**架构设计**：
```
graph LR
    User[100万请求] --> Gateway[网关/限流]
    Gateway -->|放行 1万| MQ[消息队列 (蓄水池)]
    Gateway -->|拒绝 99万| Return[返回"排队中"]
    
    MQ -->|匀速拉取 2000/s| OrderService[订单服务]
    OrderService --> DB[扣减库存]
```

1.  **拦截**：99% 的请求在网关层或前端直接被拦截。
2.  **缓冲**：1 万个有效请求写入 TDMQ（CKafka/RocketMQ），MQ 抗住瞬间高并发写。
3.  **削峰**：后端订单服务根据数据库的处理能力（如 2000 TPS），匀速从 MQ 拉取消息处理。
4.  **结果**：数据库始终运行在安全负载下，系统**“虽慢但稳”**。

---

# 第五部分：TDMQ 家族深度特性

## 一、TDMQ Pulsar：下一代云原生 MQ

### 1.1 存算分离架构
- **Broker (计算层)**：无状态，负责消息路由。扩容 Broker 可提升吞吐量。
- **Bookie (存储层)**：负责数据落盘。扩容 Bookie 可提升存储容量。
- **优势**：扩容时**无需数据迁移**（Rebalance），秒级完成，这是 Kafka 做不到的。

### 1.2 四种订阅模式 (必考点)
1.  **Exclusive (独占)**：一个 Topic 只能被一个消费者消费。保证全局有序，但无法扩展消费能力。
2.  **Failover (灾备)**：主消费者挂了，备消费者接手。
3.  **Shared (共享)**：多个消费者轮询消费消息。**消费能力最强**，但不保证顺序。
4.  **Key_Shared**：相同 Key 的消息发给同一个消费者。**既能扩展消费能力，又能保证 Key 级别的有序性**。

## 二、TDMQ CKafka：大数据吞吐之王

- **零拷贝 (Zero Copy)**：利用 Linux `sendfile` 技术，数据直接从磁盘复制到网卡，不经过用户态内存，极大降低 CPU 消耗。
- **页缓存 (Page Cache)**：利用操作系统内存加速读写。
- **适用场景**：日志收集（ELK）、大数据流计算（Spark/Flink），**吞吐量百万级**。

## 三、TDMQ RocketMQ：金融级一致性

- **事务消息**：
    1. 生产者发送“半消息”（对消费者不可见）。
    2. 执行本地事务（如扣款）。
    3. 提交或回滚消息。
    - **价值**：确保“本地事务执行”与“消息发送”的**原子性**，解决分布式事务难题（如支付成功后必须发货）。
- **延迟消息**：支持特定等级的延迟投递（如下单 30 分钟未支付自动关闭）。

---

# 课程总结与实践建议

1.  **架构优化核心**：
    - **静态资源**放 CDN。
    - **读多写少**加 Redis。
    - **高并发写**用 MQ 削峰。
    - **非核心流程**用 MQ 异步。

2.  **TDMQ 选型口诀**：
    - **日志大数据**选 **CKafka**。
    - **金融交易**选 **RocketMQ**（事务消息）。
    - **跨地域/存算分离**选 **Pulsar**。
    - **复杂路由**选 **RabbitMQ**。

3.  **运维监控**：
    - 务必监控 Redis 的 **内存使用率** 和 **Big Key**。
    - 务必监控 MQ 的 **消息堆积量 (Lag)**。

本章课程到此结束。通过本章的学习，您不仅掌握了性能优化的理论，更学会了在真实的高并发场景下如何运用缓存和消息队列进行“排兵布阵”。下一章，我们将进入 **3.3 应用容器化改造**。