# 5.2 云组件与迁移工具

## 课程简介

云迁移不是简单的“复制粘贴”，而是涉及计算、存储、网络、数据库、中间件等全栈资源的映射与重构。本课程将详细介绍各类云组件（如 AWS EC2, 阿里云 OSS）到腾讯云的映射关系，深入讲解腾讯云迁移服务平台（MSP）的核心能力，并针对主机、K8s、数据库、中间件及大数据场景提供标准化的迁移工具与最佳实践方案。

### 学习目标

通过本课程的学习，您将能够：

- ✓ **掌握组件映射**：熟悉主流云厂商（AWS/阿里/华为）资源到腾讯云的对标产品。
- ✓ **运用 MSP 平台**：熟练使用 MSP 进行资源调研、成本评估及迁移管理。
- ✓ **实施主机迁移**：掌握镜像导入、在线迁移等多种主机上云方式。
- ✓ **实施 K8s 迁移**：学会使用 Velero 迁移集群资源，使用 TCR 同步镜像。
- ✓ **实施数据迁移**：精通 DTS（数据库）、FileYrook（文件）、MSP（对象存储）等工具。
- ✓ **实施大数据迁移**：掌握 HDFS、Hive、Elasticsearch 及 Kafka 的迁移方案。

---

# 第一部分：云组件映射与迁移工具矩阵

> **本部分导读**  
> 不同云厂商的产品名称各异，但底层技术逻辑相通。掌握“翻译”能力是架构师的基本功。

## 一、常见云组件映射表

| 类别 | 阿里云 | AWS | 华为云 | **腾讯云 (目标)** | **推荐迁移工具** |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **计算** | ECS | EC2 | ECS | **CVM (云服务器)** | HyperMotion, Go2TencentCloud |
| **容器** | ACK | EKS | CCE | **TKE (容器服务)** | Velero, TCR 镜像同步 |
| **对象存储** | OSS | S3 | OBS | **COS (对象存储)** | MSP, COS Migration |
| **文件存储** | NAS | EFS | SFS | **CFS (文件存储)** | FileYrook, Rsync |
| **关系数据库** | RDS | RDS | RDS | **CDB / TDSQL** | **DTS (数据传输服务)** |
| **缓存** | Redis | ElastiCache | DCS | **TencentDB for Redis** | DTS, Redis-port |
| **消息队列** | Kafka | MSK | DMS | **TDMQ CKafka** | MirrorMaker, Connector |

---

# 第二部分：迁移服务平台 (MSP)

> **本部分导读**  
> MSP (Migration Service Platform) 是腾讯云提供的一站式迁移管理平台，集成了调研、评估、迁移、验证全流程工具。

## 一、核心功能模块

### 1.1 资源调研与评估
- **资源扫描工具**：支持在线 API 扫描（AWS/阿里云）和离线脚本扫描（Linux/Windows），自动生成资源清单（Excel）。
- **产品规格对照表**：自动映射源端规格（如 `c5.large`）到腾讯云推荐规格（如 `S5.MEDIUM4`），并提供成本对比。

### 1.2 迁移工具箱
MSP 集成了多种官方及合作伙伴工具：
- **主机迁移**：支持 P2V (物理机转虚拟化) 和 V2V (虚拟化转虚拟化)。
- **数据迁移**：集成 DTS、COS Migration 等工具，统一管理任务进度。
- **项目管理**：提供迁移大盘，实时监控各业务线的迁移状态。

---

# 第三部分：计算与容器迁移

## 一、主机 (CVM) 迁移方案

### 1.1 三种迁移模式
1.  **重新部署 (Re-deploy)**：
    - 适用：无状态应用、已有自动化部署脚本。
    - 方法：在腾讯云新购 CVM，重新运行 CI/CD 流水线。
2.  **镜像迁移 (Image Import)**：
    - 适用：需要保留操作系统配置，业务量不大。
    - 方法：将源端系统盘制作成镜像（RAW/QCOW2），导入腾讯云镜像控制台。
3.  **在线热迁移 (Live Migration)**：
    - 适用：海量服务器，业务停机时间敏感。
    - 工具：**HyperMotion** 或 **Go2TencentCloud**。在源端安装 Agent，全量复制数据后，实时同步增量数据，最后切换割接。

## 二、Kubernetes (K8s) 迁移方案

```
graph LR
    Source[源 K8s 集群] -- 1. 备份资源 YAML --> Velero[Velero 备份工具]
    Source -- 2. 同步镜像 --> TCR[腾讯云 TCR]
    
    Velero -- 3. 恢复资源 YAML --> Target[目标 TKE 集群]
    TCR -- 4. 拉取镜像 --> Target
    
    Target -- 5. 切换流量 DNS/Ingress --> Users[用户]
```

### 关键步骤
1.  **环境准备**：创建 TKE 集群，配置 VPC 和网络。
2.  **镜像迁移**：使用 `image-transfer` 或 TCR 的同步规则，将镜像从 Docker Hub/ACR 同步到 TCR。
3.  **资源迁移**：使用 **Velero** 备份源集群的 Deployment、Service、ConfigMap 等资源，并在 TKE 恢复。
4.  **持久化数据**：对于 PVC 数据，需结合快照或存储迁移工具进行搬迁。

---

# 第四部分：数据与数据库迁移

> **本部分导读**  
> 数据是迁移的核心资产，DTS 是数据库迁移的“瑞士军刀”。

## 一、数据库迁移 (DTS)

**DTS (Data Transmission Service)** 支持结构迁移、全量迁移和增量同步。

### 1.1 典型场景：MongoDB 迁移
- **源端**：MongoDB 3.x/4.x (副本集或分片集群)。
- **目标端**：腾讯云 MongoDB。
- **流程**：
    1.  **结构迁移**：自动创建 Collection 和 Index。
    2.  **全量迁移**：搬迁存量数据。
    3.  **增量同步**：持续同步 Oplog，保证数据实时一致。
    4.  **校验与切换**：停止源端写入，校验数据一致性，切换连接地址。

### 1.2 Redis 迁移的三种策略
| 策略 | 适用场景 | 流程 |
| :--- | :--- | :--- |
| **重建迁移** | 数据量小，可接受丢失 | 新建 Redis，业务双写或重新预热缓存。 |
| **停机迁移 (RDB)** | 数据量中等，允许停机 | 导出源端 RDB 文件 -> 使用 `redis-port` 导入目标端。 |
| **在线热迁移 (DTS)** | **大数据量，业务不停机** | DTS 全量+增量同步 -> 业务平滑切换。 |

## 二、对象存储迁移 (COS)

### 2.1 COS Migration 工具
- **功能**：支持将 AWS S3、阿里云 OSS、本地文件迁移到腾讯云 COS。
- **特性**：
    - **断点续传**：大文件传输中断可自动恢复。
    - **增量迁移**：对比文件修改时间，仅上传新增文件。
    - **校验**：支持 CRC64/MD5 校验，确保数据完整。

## 三、文件存储迁移 (FileYrook)

**FileYrook** 是腾讯云提供的文件迁移工具，支持 CFS、NAS、本地目录之间的数据迁移。
- **原理**：基于 Agent 的数据同步，支持多线程并发和一致性校验。

## 四、海量离线迁移 (CDM)

当数据量达到 **PB 级** 或网络带宽极低时，网络传输不可行。
- **方案**：使用 **CDM (Cloud Data Migration)** 专用迁移设备（M30/L80）。
- **流程**：申请设备 -> 寄送至客户机房 -> 本地拷贝数据 -> 寄回腾讯云数据中心 -> 上传至 COS。

---

# 第五部分：中间件与大数据迁移

## 一、Kafka 消息队列迁移

### 1.1 难点：消息有序性
- **方案 A (严格有序)**：停写源端 -> 等待消费者消费完 -> 切换生产和消费到目标端（会有停顿）。
- **方案 B (平滑迁移)**：
    - **双写/双读**：业务同时消费新旧集群。
    - **MirrorMaker**：使用 Kafka MirrorMaker 工具实时同步消息。

## 二、Elasticsearch 迁移

1.  **COS 快照 (Snapshot)**：最推荐。源端创建快照存入对象存储，目标端从快照恢复。适合大数据量。
2.  **Logstash**：配置 `input-elasticsearch` 和 `output-elasticsearch`，适合实时同步或数据清洗。
3.  **elasticdump**：适合小规模数据或迁移 Mapping/Setting。

## 三、大数据集群 (EMR) 迁移

### 3.1 HDFS 数据迁移
- **DistCP**：Hadoop 自带的分布式复制工具。`hadoop distcp hdfs://src:8020/data hdfs://dst:8020/data`。
- **冷热分离**：将历史冷数据迁移到 **COS**（使用 HDFS to COS 工具），仅将热数据迁移到新 HDFS，降低成本。

### 3.2 Hive 元数据迁移
1.  **Dump 元数据**：使用 `mysqldump` 导出 Hive Metastore 的数据库。
2.  **路径修正**：修改元数据中的 `Location` 字段，指向新 HDFS 路径。
3.  **导入**：在目标端 Hive Metastore 数据库导入 SQL。

---

# 课程总结

## 知识体系回顾
1.  **工具矩阵**：
    - 数据库 -> **DTS**
    - 对象存储 -> **MSP / COS Migration**
    - 主机 -> **Go2TencentCloud**
    - 离线海量数据 -> **CDM 设备**
2.  **核心策略**：
    - 能用 SaaS 工具（如 MSP, DTS）优先用 SaaS，减少人工操作。
    - 数据库和中间件迁移首选 **增量同步** 方案，实现平滑割接。
    - 大数据迁移需区分 **元数据** (MySQL) 和 **实际数据** (HDFS/COS)。

## 架构师实践清单 (Checklist)
- [ ] **选型**：是否已根据源端环境选择了正确的迁移工具？
- [ ] **网络**：迁移带宽是否满足时间窗口要求？（如不满足需申请专线或 CDM）。
- [ ] **校验**：每个迁移环节是否都安排了数据一致性校验（MD5/行数）？
- [ ] **回滚**：是否为数据库割接预留了反向同步链路？

本章课程到此结束。下一章，我们将进入 **5.3 迁移案例介绍及云上资源成本管理**，通过真实案例复盘迁移全过程，并学习云上成本优化之道。